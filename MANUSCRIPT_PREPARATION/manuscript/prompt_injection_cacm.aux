\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{hiddenlayer-cursor}
\citation{cve-cursor}
\citation{rehberger-copilot}
\citation{guardian-search}
\citation{owasp-llm01}
\citation{willison-trifecta}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{liu-usenix24}
\citation{jailbreakbench}
\citation{secalign}
\citation{bair-struq}
\citation{defensivetokens}
\@writefile{toc}{\contentsline {paragraph}{Contributions.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work and Strategic Context}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work and Strategic Context}{section.2}{}}
\citation{owasp-llm01}
\citation{microsoft-indirect}
\citation{jailbreak-repo}
\citation{microsoft-indirect}
\@writefile{toc}{\contentsline {paragraph}{Positioning our contribution.}{3}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Patent Landscape (Industry Signals)}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods: Multi-Phase Defense Program}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Project origin.}{3}{section*.5}\protected@file@percent }
\citation{jailbreak-repo,jailbreakbench}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Patent-informed defense motifs and how our pipeline instantiates them.}}{4}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:patents}{{1}{4}{Patent-informed defense motifs and how our pipeline instantiates them}{table.caption.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Roadmap.}{6}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Baseline prompt-injection attack success rates (ASR) by model and attack vector. Bars show percentage of successful attacks for LLaMA-2-7B (blue) and Falcon-7B (orange) across two attack types: RAG-borne (malicious instructions in retrieved documents) and schema smuggling (JSON/tool-calling exploitation). LLaMA-2-7B shows 65\% ASR on RAG-borne vs. 5\% for Falcon-7B, demonstrating that more instruction-following models are more vulnerable.}}{7}{figure.caption.15}\protected@file@percent }
\newlabel{fig:baseline}{{1}{7}{Baseline prompt-injection attack success rates (ASR) by model and attack vector. Bars show percentage of successful attacks for LLaMA-2-7B (blue) and Falcon-7B (orange) across two attack types: RAG-borne (malicious instructions in retrieved documents) and schema smuggling (JSON/tool-calling exploitation). LLaMA-2-7B shows 65\% ASR on RAG-borne vs. 5\% for Falcon-7B, demonstrating that more instruction-following models are more vulnerable}{figure.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Baseline vulnerability summary showing attack success rate (ASR) percentages for both models and attack vectors.}}{7}{table.caption.16}\protected@file@percent }
\newlabel{tab:baseline}{{2}{7}{Baseline vulnerability summary showing attack success rate (ASR) percentages for both models and attack vectors}{table.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Baseline Vulnerability (P1)}{7}{subsection.4.1}\protected@file@percent }
\newlabel{sec:baseline}{{4.1}{7}{Baseline Vulnerability (P1)}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Detector performance comparison on Phase 1 attack dataset (400 attacks, 260 benign). Grouped bars show True Positive Rate (TPR, green) and False Alarm Rate (FAR, red) as percentages for three detector types: v1 (signature-based pattern matching), v2 (structured heuristics), v3 (semantic embedding similarity). v1 achieves highest TPR (89\%) with near-zero FAR (0.5\%); v3 provides complementary coverage with 82\% TPR and 0.8\% FAR.}}{8}{figure.caption.17}\protected@file@percent }
\newlabel{fig:detectors}{{2}{8}{Detector performance comparison on Phase 1 attack dataset (400 attacks, 260 benign). Grouped bars show True Positive Rate (TPR, green) and False Alarm Rate (FAR, red) as percentages for three detector types: v1 (signature-based pattern matching), v2 (structured heuristics), v3 (semantic embedding similarity). v1 achieves highest TPR (89\%) with near-zero FAR (0.5\%); v3 provides complementary coverage with 82\% TPR and 0.8\% FAR}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Detector Efficacy and Fusion (P2--P3)}{8}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Detector complementarity analysis showing attack coverage overlap. Bars indicate: attacks caught by v1 only (signature patterns), v3 only (semantic similarity), both detectors (overlap), and missed by both. The disjoint subsets demonstrate that v1 (keyword-heavy attacks) and v3 (paraphrased attacks) provide complementary coverage, justifying OR-fusion.}}{9}{figure.caption.18}\protected@file@percent }
\newlabel{fig:complementarity}{{3}{9}{Detector complementarity analysis showing attack coverage overlap. Bars indicate: attacks caught by v1 only (signature patterns), v3 only (semantic similarity), both detectors (overlap), and missed by both. The disjoint subsets demonstrate that v1 (keyword-heavy attacks) and v3 (paraphrased attacks) provide complementary coverage, justifying OR-fusion}{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Fusion strategy comparison showing TPR and FAR for different detector combination methods. OR-fusion triggers if any detector flags the prompt (87\% TPR, 0\% FAR). AND-fusion requires all detectors to agree (55.5\% TPR, overly conservative). Majority vote with v2 adds minimal value (60\% TPR). OR-fusion provides the best precision-recall balance.}}{9}{table.caption.19}\protected@file@percent }
\newlabel{tab:fusion}{{3}{9}{Fusion strategy comparison showing TPR and FAR for different detector combination methods. OR-fusion triggers if any detector flags the prompt (87\% TPR, 0\% FAR). AND-fusion requires all detectors to agree (55.5\% TPR, overly conservative). Majority vote with v2 adds minimal value (60\% TPR). OR-fusion provides the best precision-recall balance}{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Threshold Invariance (P4)}{9}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Threshold invariance demonstration. Lines show TPR (green) and FAR (red) as v3's internal similarity threshold varies from 0.1 to 0.7. OR-fusion maintains stable 87\% TPR and 0\% FAR across all thresholds, eliminating the need for careful threshold tuning—a key operational advantage.}}{10}{figure.caption.20}\protected@file@percent }
\newlabel{fig:threshold}{{4}{10}{Threshold invariance demonstration. Lines show TPR (green) and FAR (red) as v3's internal similarity threshold varies from 0.1 to 0.7. OR-fusion maintains stable 87\% TPR and 0\% FAR across all thresholds, eliminating the need for careful threshold tuning—a key operational advantage}{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Benign obfuscation false alarm rates (FAR) on 260 clean queries with synthetic obfuscation applied (P6a). Each row shows a different detector configuration; FAR values are percentages. Production configuration (Normalizer+v3) achieves 0.77\% FAR ($<$1\%), suitable for low-false-positive deployment.}}{10}{table.caption.23}\protected@file@percent }
\newlabel{tab:benign}{{4}{10}{Benign obfuscation false alarm rates (FAR) on 260 clean queries with synthetic obfuscation applied (P6a). Each row shows a different detector configuration; FAR values are percentages. Production configuration (Normalizer+v3) achieves 0.77\% FAR ($<$1\%), suitable for low-false-positive deployment}{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Learning and Normalization (P5--P6a)}{10}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Learning gain from logistic regression fusion. Bars compare OR-fusion baseline (87\% TPR) to learned logistic fusion (99\% TPR), both achieving 0\% FAR. The learned model uses detector confidence scores and binary outputs as features, showing a 12-point TPR improvement.}}{11}{figure.caption.21}\protected@file@percent }
\newlabel{fig:learning}{{5}{11}{Learning gain from logistic regression fusion. Bars compare OR-fusion baseline (87\% TPR) to learned logistic fusion (99\% TPR), both achieving 0\% FAR. The learned model uses detector confidence scores and binary outputs as features, showing a 12-point TPR improvement}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces False alarm rates on benign inputs subjected to obfuscation (P6a). Heatmap shows FAR (\%) across obfuscation types (rows: homoglyphs, Unicode mix, zero-width, etc.) and detector configurations (columns). Color intensity indicates FAR severity (red=high, green=low). Normalizer+v3 achieves 0.77\% FAR consistently; v1 without normalization suffers 23\% FAR on obfuscated text.}}{12}{figure.caption.22}\protected@file@percent }
\newlabel{fig:obfuscation}{{6}{12}{False alarm rates on benign inputs subjected to obfuscation (P6a). Heatmap shows FAR (\%) across obfuscation types (rows: homoglyphs, Unicode mix, zero-width, etc.) and detector configurations (columns). Color intensity indicates FAR severity (red=high, green=low). Normalizer+v3 achieves 0.77\% FAR consistently; v1 without normalization suffers 23\% FAR on obfuscated text}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Generalization and Adversaries (P6b--P6c)}{12}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary and next steps.}{12}{section*.27}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Novel attack detection by category (P6b, 65 unseen attacks). Horizontal bars show TPR (\%) for each attack type. Multi-turn dialogue attacks (30\% TPR): exploit back-and-forth conversation. Context-confusion (35\% TPR): mix user/system role instructions. Semantic paraphrasing (65\% TPR): rephrase known attacks. Direct hijacking (55\% TPR): goal manipulation without explicit markers. Overall TPR: 49.2\%.}}{13}{figure.caption.24}\protected@file@percent }
\newlabel{fig:novel}{{7}{13}{Novel attack detection by category (P6b, 65 unseen attacks). Horizontal bars show TPR (\%) for each attack type. Multi-turn dialogue attacks (30\% TPR): exploit back-and-forth conversation. Context-confusion (35\% TPR): mix user/system role instructions. Semantic paraphrasing (65\% TPR): rephrase known attacks. Direct hijacking (55\% TPR): goal manipulation without explicit markers. Overall TPR: 49.2\%}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}System Architecture and Deployment}{13}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Performance and Resource Profile (P7--P8)}{13}{subsection.5.1}\protected@file@percent }
\newlabel{sec:overhead}{{5.1}{13}{Performance and Resource Profile (P7--P8)}{subsection.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Generalization gap analysis (Monitoring / OR-fusion). Bars show TPR (\%): known attacks from P1 (87\% TPR with Monitoring/OR-fusion), novel attacks (49\%). The $\sim $38-point gap highlights limits in generalizing beyond training exemplars. (The optional learned logistic fusion reached 99\% on P1 but is not deployed.)}}{14}{figure.caption.25}\protected@file@percent }
\newlabel{fig:gap}{{8}{14}{Generalization gap analysis (Monitoring / OR-fusion). Bars show TPR (\%): known attacks from P1 (87\% TPR with Monitoring/OR-fusion), novel attacks (49\%). The $\sim $38-point gap highlights limits in generalizing beyond training exemplars. (The optional learned logistic fusion reached 99\% on P1 but is not deployed.)}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Adversarial evasion technique effectiveness (P6c, n=30). Multi-step instruction decomposition 75\%, encoding chains 70\%, semantic obfuscation 65\%, paraphrasing 60\%, fragmentation 55\%.}}{15}{figure.caption.26}\protected@file@percent }
\newlabel{fig:adversarial}{{9}{15}{Adversarial evasion technique effectiveness (P6c, n=30). Multi-step instruction decomposition 75\%, encoding chains 70\%, semantic obfuscation 65\%, paraphrasing 60\%, fragmentation 55\%}{figure.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Phase 7--8 quantitative overhead showing latency (milliseconds) and resource consumption on GPU-accelerated deployment (NVIDIA GeForce RTX 4070 Laptop GPU, Intel Core Ultra 9 185H, Python 3.9). Median and 90th percentile latencies provided for each component; resource metrics include peak GPU utilization (\%), memory footprint (MB), and throughput (queries/second).}}{15}{table.caption.29}\protected@file@percent }
\newlabel{tab:overhead}{{5}{15}{Phase 7--8 quantitative overhead showing latency (milliseconds) and resource consumption on GPU-accelerated deployment (NVIDIA GeForce RTX 4070 Laptop GPU, Intel Core Ultra 9 185H, Python 3.9). Median and 90th percentile latencies provided for each component; resource metrics include peak GPU utilization (\%), memory footprint (MB), and throughput (queries/second)}{table.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Using Monitoring mode in practice.}{15}{section*.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The ``LLM Firewall'' pipeline architecture. All incoming prompts are first normalized (to remove Unicode obfuscations and homoglyphs), then checked in parallel by a signature rule base (v1, pattern matching on injection markers) and a semantic similarity model (v3, embedding-based detection). If either detector flags the prompt (OR-fusion logic), the input is deemed malicious and can be blocked or logged; otherwise it is forwarded to the LLM. This setup adds minimal latency ($<$1\,ms with GPU acceleration). \textbf  {Deployment modes:} \emph  {Production} (Normalizer+v3 only): minimal false alarms ($<$1\% FAR), 82\% TPR on known attacks. \emph  {Monitoring} (Normalizer+v1+v3): higher recall (87\% on known, 49\% on novel attacks), used for auditing and detector improvement.}}{16}{figure.caption.28}\protected@file@percent }
\newlabel{fig:arch}{{10}{16}{The ``LLM Firewall'' pipeline architecture. All incoming prompts are first normalized (to remove Unicode obfuscations and homoglyphs), then checked in parallel by a signature rule base (v1, pattern matching on injection markers) and a semantic similarity model (v3, embedding-based detection). If either detector flags the prompt (OR-fusion logic), the input is deemed malicious and can be blocked or logged; otherwise it is forwarded to the LLM. This setup adds minimal latency ($<$1\,ms with GPU acceleration). \textbf {Deployment modes:} \emph {Production} (Normalizer+v3 only): minimal false alarms ($<$1\% FAR), 82\% TPR on known attacks. \emph {Monitoring} (Normalizer+v1+v3): higher recall (87\% on known, 49\% on novel attacks), used for auditing and detector improvement}{figure.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Recommended configurations for deployment. Production mode is tuned for high precision (almost no false alarms, accepting some missed attacks); Monitoring mode is tuned for high recall (catches more attacks, including novel ones, but with higher false alarm rate for auditing and model improvement).}}{16}{table.caption.30}\protected@file@percent }
\newlabel{tab:configs}{{6}{16}{Recommended configurations for deployment. Production mode is tuned for high precision (almost no false alarms, accepting some missed attacks); Monitoring mode is tuned for high recall (catches more attacks, including novel ones, but with higher false alarm rate for auditing and model improvement)}{table.caption.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Deployment guidance.}{17}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Key design principles.}{17}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Best practices checklist.}{17}{section*.34}\protected@file@percent }
\citation{bair-struq,secalign}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion and Lessons}{18}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why input-side filtering when models have built-in safety?}{18}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Detector strengths and brittleness.}{18}{section*.36}\protected@file@percent }
\citation{bair-struq}
\citation{secalign}
\citation{jailbreakbench}
\citation{secalign}
\@writefile{toc}{\contentsline {section}{\numberline {7}Limitations and Future Work}{19}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Novel attack coverage.}{19}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Multi-turn and conversational context.}{19}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Scope and modality.}{19}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Evaluation setting.}{19}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Future directions.}{19}{section*.41}\protected@file@percent }
\bibstyle{ACM-Reference-Format}
\bibdata{prompt_injection_cacm}
\bibcite{bair-struq}{{1}{2025}{{BAIR (Berkeley Artificial Intelligence Research)}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{20}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Acknowledgments}{20}{section*.44}\protected@file@percent }
\bibcite{jailbreakbench}{{2}{2024}{{Chao et~al\mbox  {.}}}{{}}}
\bibcite{defensivetokens}{{3}{2025a}{{Chen et~al\mbox  {.}}}{{}}}
\bibcite{secalign}{{4}{2025b}{{Chen et~al\mbox  {.}}}{{}}}
\bibcite{hiddenlayer-cursor}{{5}{2025}{{HiddenLayer}}{{}}}
\bibcite{jailbreak-repo}{{6}{2024}{{L1B3RT4S Community}}{{}}}
\bibcite{liu-usenix24}{{7}{2024}{{Liu et~al\mbox  {.}}}{{}}}
\bibcite{microsoft-indirect}{{8}{2025}{{Microsoft Security Response Center}}{{}}}
\bibcite{owasp-llm01}{{9}{2025}{{OWASP GenAI Security Project}}{{}}}
\bibcite{rehberger-copilot}{{10}{2024}{{Rehberger}}{{}}}
\bibcite{cve-cursor}{{11}{2025}{{Tenable Research}}{{}}}
\bibcite{guardian-search}{{12}{2024}{{The Guardian}}{{}}}
\bibcite{willison-trifecta}{{13}{2025}{{Willison}}{{}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.34999pt}
\newlabel{tocindent3}{0pt}
\newlabel{tocindent4}{0pt}
\newlabel{tocindent5}{0pt}
\@writefile{toc}{\contentsline {section}{References}{21}{section*.46}\protected@file@percent }
\newlabel{TotPages}{{21}{21}{}{page.21}{}}
\gdef \@abspage@last{21}
