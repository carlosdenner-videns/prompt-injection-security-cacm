@misc{owasp-llm01,
  author = {{OWASP GenAI Security Project}},
  title = {LLM01:2025 Prompt Injection},
  year = {2025},
  howpublished = {\url{https://genai.owasp.org/llmrisk/llm01-prompt-injection/}},
  note = {Accessed Nov. 3, 2025}
}

@inproceedings{liu-usenix24,
  author = {Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  title = {Formalizing and Benchmarking Prompt Injection Attacks and Defenses},
  booktitle = {Proceedings of the 33rd USENIX Security Symposium (USENIX Security '24)},
  year = {2024},
  publisher = {USENIX Association}
}

@article{secalign,
  author = {Chen, Sizhe and Zharmagambetov, Arman and Mahloujifar, Saeed and Chaudhuri, Kamalika and Wagner, David and Guo, Chuan},
  title = {SecAlign: Defending Against Prompt Injection with Preference Optimization},
  journal = {arXiv},
  year = {2025},
  volume = {2410.05451},
  note = {v3, Last revised Jul. 3, 2025; accessed Nov. 3, 2025},
  doi = {10.48550/arXiv.2410.05451},
  url = {https://arxiv.org/abs/2410.05451}
}

@article{defensivetokens,
  author = {Chen, Sizhe and Wang, Yizhu and Carlini, Nicholas and Sitawarin, Chawin and Wagner, David},
  title = {Defending Against Prompt Injection With a Few DefensiveTokens},
  journal = {arXiv},
  year = {2025},
  volume = {2507.07974},
  note = {v2, Last revised Aug. 25, 2025; accessed Nov. 3, 2025},
  doi = {10.48550/arXiv.2507.07974},
  url = {https://arxiv.org/abs/2507.07974}
}

@inproceedings{jailbreakbench,
  author = {Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Pappas, George J. and Tramer, Florian and Wong, Eric},
  title = {JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models},
  booktitle = {NeurIPS 2024 Datasets and Benchmarks Track},
  year = {2024},
  url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/63092d79154adebd7305dfd498cbff70-Abstract-Datasets-and-Benchmarks-Track.html},
  note = {Accessed Nov. 3, 2025}
}

@misc{bair-struq,
  author = {{BAIR (Berkeley Artificial Intelligence Research)}},
  title = {Defending against Prompt Injection with Structured Queries (StruQ) and Preference Optimization (SecAlign)},
  year = {2025},
  howpublished = {Blog post},
  month = {April},
  day = {11},
  url = {https://bair.berkeley.edu/blog/2025/04/11/prompt-injection-defense/},
  note = {Accessed Nov. 3, 2025}
}

@misc{hiddenlayer-cursor,
  author = {{HiddenLayer}},
  title = {How Hidden Prompt Injections Can Hijack AI Code Assistants Like Cursor},
  year = {2025},
  howpublished = {\url{https://hiddenlayer.com/research/prompt-injection-cursor/}},
  note = {Accessed Nov. 4, 2025}
}

@misc{cve-cursor,
  author = {{Tenable Research}},
  title = {CVE-2025-54135 (CurXecute) and CVE-2025-54136 (MCPoison): Cursor AI IDE Vulnerabilities},
  year = {2025},
  howpublished = {BleepingComputer},
  url = {https://www.bleepingcomputer.com/news/security/cursor-ai-ide-flaws-exploited-prompt-injection/},
  note = {Accessed Nov. 4, 2025}
}

@misc{rehberger-copilot,
  author = {Rehberger, Johann},
  title = {Microsoft 365 Copilot: From Prompt Injection to Exfiltration of Personal Information},
  year = {2024},
  howpublished = {EmbraceTheRed},
  url = {https://embracethered.com/blog/posts/2024/m365-copilot-prompt-injection-data-exfiltration/},
  note = {Accessed Nov. 4, 2025}
}

@misc{guardian-search,
  author = {{The Guardian}},
  title = {ChatGPT search tool vulnerable to manipulation and deception, tests show},
  year = {2024},
  howpublished = {\url{https://www.theguardian.com/technology/2024/nov/07/chatgpt-search-hidden-text-manipulation}},
  note = {Accessed Nov. 4, 2025}
}

@misc{willison-trifecta,
  author = {Willison, Simon},
  title = {The Lethal Trifecta for AI Agents},
  year = {2025},
  howpublished = {Simon Willison's Weblog},
  url = {https://simonwillison.net/2025/Jan/14/lethal-trifecta/},
  note = {Accessed Nov. 4, 2025}
}

@misc{microsoft-indirect,
  author = {{Microsoft Security Response Center}},
  title = {How Microsoft Defends Against Indirect Prompt Injection Attacks},
  year = {2025},
  howpublished = {\url{https://msrc.microsoft.com/blog/2025/01/indirect-prompt-injection-defense/}},
  note = {Accessed Nov. 4, 2025}
}

@misc{jailbreak-repo,
  author = {{L1B3RT4S Community}},
  title = {Jailbreak Prompt Collection},
  year = {2024},
  howpublished = {GitHub Repository},
  url = {https://github.com/elder-plinius/L1B3RT4S},
  note = {15k+ stars; accessed Nov. 4, 2025}
}
